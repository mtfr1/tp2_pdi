{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    ax.imshow(img, cmap=plt.cm.gray)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando as classes\n",
    "MAIN_DIR = \"frutas_dataset_train\"\n",
    "y = [name for name in os.listdir(MAIN_DIR) if os.path.isdir(os.path.join(MAIN_DIR, name))]\n",
    "result = [os.path.join(dp, f) for dp, dn, filenames in os.walk(MAIN_DIR) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "#transformar as labels de string para ints\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qtde de arquivos por pasta\n",
    "num_files = []\n",
    "for i in y:\n",
    "    DIR = \"frutas_dataset_train/\" + i + \"/\"\n",
    "    num_files.append(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))\n",
    "\n",
    "X = np.zeros((len(result), 10)) #n_samples x n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o target label == classes das frutas\n",
    "k = []\n",
    "for i in range(len(y)):\n",
    "    for j in range(num_files[i]):\n",
    "        k.append(encoded[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar a LBP das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando a matriz geral\n",
    "for i in range(len(result)):\n",
    "    im = color.rgb2gray(io.imread(result[i]))\n",
    "    lbp = feature.texture.local_binary_pattern(im, 8, 2, method='uniform')\n",
    "    histogram = scipy.stats.itemfreq(lbp)\n",
    "    x = histogram[:,1]\n",
    "    norm_hist = normalize(x[:,np.newaxis], axis=0).ravel()\n",
    "    X[i,:] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando estado da matriz X e do vetor de target labels k\n",
    "np.savetxt(\"extracted_features/x_lbp.txt\", X, delimiter=\";\")\n",
    "np.savetxt(\"extracted_features/k.txt\", k, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler a LBP do txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recuperar estado\n",
    "X_lbp = np.genfromtxt('extracted_features/x_lbp.txt', delimiter=';')\n",
    "k = np.genfromtxt('extracted_features/k.txt', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_lbp_train, X_lbp_test, k_lbp_train, k_lbp_test = train_test_split(X_lbp, k, test_size=0.5) #test size = 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_lbp = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_lbp.fit(X_lbp_train, k_lbp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_lbp_pred = knn_lbp.predict(X_lbp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 0.7867298578199052\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Taxa de acerto:\", metrics.accuracy_score(k_lbp_test, k_lbp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_lbp_hist(im):\n",
    "    lbp = feature.texture.local_binary_pattern(im, 8, 2, method='uniform')\n",
    "    histogram = scipy.stats.itemfreq(lbp)\n",
    "    x = histogram[:,1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(encoded, y, num):\n",
    "    for i in range(len(encoded)):\n",
    "        if(encoded[i] == num):\n",
    "            break\n",
    "    return y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cashew\n"
     ]
    }
   ],
   "source": [
    "im = color.rgb2gray(io.imread(\"cashew_039.jpg\"))\n",
    "x = calcula_lbp_hist(im)\n",
    "a = knn_lbp.predict(x.reshape(1,-1))\n",
    "print(get_class(encoded, y, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watermelon\n"
     ]
    }
   ],
   "source": [
    "im = color.rgb2gray(io.imread(\"watermelon_063.jpg\"))\n",
    "x = calcula_lbp_hist(im)\n",
    "a = knn_lbp.predict(x.reshape(1,-1))\n",
    "print(get_class(encoded, y, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar a matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "k_pred = knn_lbp.predict(X_lbp_test)\n",
    "conf_matrix = confusion_matrix(k_lbp_test, k_lbp_pred)\n",
    "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"confusion_matrix_script/input_lbp.csv\", conf_matrix, delimiter=';', fmt='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar o Histograma de Cores das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = np.zeros((len(result), 768))\n",
    "\n",
    "for i in range(len(result)):\n",
    "    im = skimage.img_as_float(io.imread(result[i]))\n",
    "    hist_r = exposure.histogram(im[:,:,0])\n",
    "    hist_g = exposure.histogram(im[:,:,1])\n",
    "    hist_b = exposure.histogram(im[:,:,2])\n",
    "    x = np.append(hist_r[0], hist_g[0])\n",
    "    x = np.append(x, hist_b[0])\n",
    "    X_hist[i,:] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"extracted_features/x_hist.txt\", X_hist, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler o Histograma de Cor do txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = np.genfromtxt('extracted_features/x_hist.txt', delimiter=';')\n",
    "k = np.genfromtxt('extracted_features/k.txt', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist_train, X_hist_test, k_hist_train, k_hist_test = train_test_split(X_hist, k, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hist = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_hist.fit(X_hist_train, k_hist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hist_pred = knn_hist.predict(X_hist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 0.6034755134281201\n"
     ]
    }
   ],
   "source": [
    "print(\"Taxa de acerto:\", metrics.accuracy_score(k_hist_test, k_hist_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_hist(im):\n",
    "    hist_r = exposure.histogram(im[:,:,0])\n",
    "    hist_g = exposure.histogram(im[:,:,1])\n",
    "    hist_b = exposure.histogram(im[:,:,2])\n",
    "    x = np.append(hist_r[0], hist_g[0])\n",
    "    x = np.append(x, hist_b[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cashew\n"
     ]
    }
   ],
   "source": [
    "im = skimage.img_as_float(io.imread(\"cashew_039.jpg\"))\n",
    "x = calcula_hist(im)\n",
    "a = knn_hist.predict(x.reshape(1,-1))\n",
    "print(get_class(encoded, y, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watermelon\n"
     ]
    }
   ],
   "source": [
    "im = skimage.img_as_float(io.imread(\"watermelon_063.jpg\"))\n",
    "x = calcula_hist(im)\n",
    "a = knn_hist.predict(x.reshape(1,-1))\n",
    "print(get_class(encoded, y, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange\n"
     ]
    }
   ],
   "source": [
    "im = skimage.img_as_float(io.imread(\"fuji.gif\"))\n",
    "x = calcula_hist(im)\n",
    "a = knn_hist.predict(x.reshape(1,-1))\n",
    "print(get_class(encoded, y, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar a matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_hist = confusion_matrix(k_hist_test, k_hist_pred)\n",
    "conf_matrix_hist = conf_matrix_hist.astype('float') / conf_matrix_hist.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"confusion_matrix_script/input_hist.csv\", conf_matrix_hist, delimiter=';', fmt='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haralick Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_har = np.zeros((len(result), 20))\n",
    "for i in range(len(result)):\n",
    "    x = []\n",
    "    im = skimage.img_as_ubyte(color.rgb2gray(io.imread(result[i])))\n",
    "    f = feature.texture.greycomatrix(im, [1,2], [0, np.pi/2], 256, symmetric=True, normed=True)\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'contrast')[0,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'contrast')[0,1])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'contrast')[1,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'contrast')[1,1])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'contrast')[0,2])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'contrast')[0,3])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[0,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[0,1])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[1,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[1,1])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[0,2])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'dissimilarity')[0,3])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[0,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[0,1])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[1,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[1,1])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[0,2])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'homogeneity')[0,3])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'ASM')[0,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'ASM')[0,1])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'ASM')[1,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'ASM')[1,1])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'ASM')[0,2])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'ASM')[0,3])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'energy')[0,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'energy')[0,1])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'energy')[1,0])\n",
    "    x.append(feature.texture.greycoprops(f, prop = 'energy')[1,1])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'energy')[0,2])\n",
    "#     x.append(feature.texture.greycoprops(f, prop = 'energy')[0,3])\n",
    "    X_har[i,:] = x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"extracted_features/x_har.txt\", X_har, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler do txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_har = np.genfromtxt(\"extracted_features/x_har.txt\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.genfromtxt('extracted_features/k.txt', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_har_train, X_har_test, k_har_train, k_har_test = train_test_split(X_har, k, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_har = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_har.fit(X_har_train, k_har_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_har_pred = knn_har.predict(X_har_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: 0.5521327014218009\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Taxa de acerto:\", metrics.accuracy_score(k_har_test, k_har_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
